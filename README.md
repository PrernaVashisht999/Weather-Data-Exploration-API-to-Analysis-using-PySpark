# Weather-Data-Exploration-API-to-Analysis-using-PySpark
This project focuses on analyzing real-time weather data for Four Oaks, North Carolina, fetched using the RapidAPI. Leveraging PySpark in the Databricks Community Edition environment, the dataset was processed to extract meaningful insights about various weather parameters such as temperature, humidity, wind speed, cloud cover, and weather descriptions. The project began with defining a custom schema for clean data ingestion into a Spark DataFrame. Missing values were handled efficiently using techniques like filling with mean values for numerical columns. Various PySpark functions were used to explore the dataset—checking for nulls, filtering records based on specific conditions (e.g., temperature above 75°F or cloud cover above 50%), and analyzing weather patterns by grouping and sorting data. Special focus was given to datetime manipulation, such as extracting month names and day-of-month values, to identify trends like frequent cloudy days or monthly weather distribution. The entire workflow—from API integration to data transformation and insight extraction—was implemented using PySpark’s core functionalities. This project highlights practical applications of data cleaning, transformation, and exploratory data analysis in a big data environment. It demonstrates proficiency in using APIs, working with large-scale data using Spark, and drawing insights from real-world weather information in a structured and scalable manner.


